{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f48aa8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: /Users/hambati/Desktop/transparent_medical_ai/notebooks/C:\\Users\\shyam\\Desktop\\SSM\\CSC594\\Project\\datasets/Training\n",
      "Test : /Users/hambati/Desktop/transparent_medical_ai/notebooks/C:\\Users\\shyam\\Desktop\\SSM\\CSC594\\Project\\datasets/Testing\n",
      "Artifacts -> /Users/hambati/Desktop/transparent_medical_ai/notebooks/C:\\Users\\shyam\\Desktop\\SSM\\CSC594\\Project\\datasets/_artifacts\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\shyam\\\\Desktop\\\\SSM\\\\CSC594\\\\Project\\\\datasets/Training'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata_preprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_datasets\n\u001b[32m     10\u001b[39m DEVICE = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUsing device:\u001b[39m\u001b[33m\"\u001b[39m, DEVICE)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/transparent_medical_ai/notebooks/data_preprocessing.py:78\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(rows)\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# In[ ]:\u001b[39;00m\n\u001b[32m     75\u001b[39m \n\u001b[32m     76\u001b[39m \n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# Scan dataset → DataFrames & save raw metadata\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m train_df = scan_split(TRAIN_DIR, \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     79\u001b[39m test_df  = scan_split(TEST_DIR,  \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     80\u001b[39m meta = pd.concat([train_df, test_df], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/transparent_medical_ai/notebooks/data_preprocessing.py:54\u001b[39m, in \u001b[36mscan_split\u001b[39m\u001b[34m(split_dir, split_name)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mscan_split\u001b[39m(split_dir: Path, split_name: \u001b[38;5;28mstr\u001b[39m) -> pd.DataFrame:\n\u001b[32m     53\u001b[39m     rows = []\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m cls_dir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m split_dir.iterdir() \u001b[38;5;28;01mif\u001b[39;00m p.is_dir()):\n\u001b[32m     55\u001b[39m         label = cls_dir.name\n\u001b[32m     56\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m cls_dir.rglob(\u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/transparent_medical_ai/notebooks/data_preprocessing.py:54\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mscan_split\u001b[39m(split_dir: Path, split_name: \u001b[38;5;28mstr\u001b[39m) -> pd.DataFrame:\n\u001b[32m     53\u001b[39m     rows = []\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m cls_dir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m split_dir.iterdir() \u001b[38;5;28;01mif\u001b[39;00m p.is_dir()):\n\u001b[32m     55\u001b[39m         label = cls_dir.name\n\u001b[32m     56\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m cls_dir.rglob(\u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenvconda/lib/python3.12/pathlib.py:1056\u001b[39m, in \u001b[36mPath.iterdir\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34miterdir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1051\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Yield path objects of the directory contents.\u001b[39;00m\n\u001b[32m   1052\u001b[39m \n\u001b[32m   1053\u001b[39m \u001b[33;03m    The children are yielded in arbitrary order, and the\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[33;03m    special entries '.' and '..' are not included.\u001b[39;00m\n\u001b[32m   1055\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m os.listdir(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1057\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_child_relpath(name)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\shyam\\\\Desktop\\\\SSM\\\\CSC594\\\\Project\\\\datasets/Training'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from data_preprocessing import load_datasets\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4043b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#                   CNN MODEL\n",
    "# ============================================================\n",
    "\n",
    "class MRICNN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # 224 → 112\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # 112 → 56\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # 56 → 28\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # 28 → 14\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # 14 → 7\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((1,1))\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create model\n",
    "num_classes = len(train_ds.labels)\n",
    "model = MRICNN(num_classes).to(DEVICE)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f96caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#               LOSS, OPTIMIZER, SCHEDULER\n",
    "# ============================================================\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # or weighted if imbalanced\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "scaler = GradScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0354390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#                   TRAINING LOOP\n",
    "# ============================================================\n",
    "\n",
    "def train_one_epoch(model, loader):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x, y in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        preds = logits.argmax(1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += x.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    running_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            with autocast():\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "            preds = logits.argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += x.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca9fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#                   TRAINING DRIVER\n",
    "# ============================================================\n",
    "\n",
    "EPOCHS = 20\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader)\n",
    "    val_loss, val_acc = validate(model, val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), ARTIFACTS_DIR / \"best_custom_cnn.pt\")\n",
    "        print(\"Saved best model!\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8902d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#                   TEST EVALUATION\n",
    "# ============================================================\n",
    "\n",
    "model.load_state_dict(torch.load(ARTIFACTS_DIR / \"best_custom_cnn.pt\"))\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(DEVICE)\n",
    "        logits = model(x)\n",
    "        preds = logits.argmax(1).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_targets.append(y.numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_targets = np.concatenate(all_targets)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_targets, all_preds, target_names=train_ds.labels))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(all_targets, all_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0646216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m2\u001b[0m\u001b[1;32m channel Terms of Service accepted\u001b[0m\n",
      "Retrieving notices: done\n",
      "Channels:\n",
      " - pytorch\n",
      " - defaults\n",
      "Platform: osx-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 25.5.1\n",
      "    latest version: 25.7.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda3/envs/myenvconda\n",
      "\n",
      "  added / updated specs:\n",
      "    - cpuonly\n",
      "    - pytorch\n",
      "    - torchaudio\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    cpuonly-2.0                |                0           2 KB  pytorch\n",
      "    filelock-3.17.0            |  py312hecd8cb5_0          38 KB\n",
      "    gmpy2-2.2.1                |  py312h2cec913_0         218 KB\n",
      "    libjpeg-turbo-2.0.0        |       hca72f7f_0         424 KB\n",
      "    mpmath-1.3.0               |  py312hecd8cb5_0         974 KB\n",
      "    networkx-3.4.2             |  py312hecd8cb5_0         3.1 MB\n",
      "    pytorch-2.2.2              |         py3.12_0        90.0 MB  pytorch\n",
      "    pytorch-mutex-1.0          |              cpu           3 KB  pytorch\n",
      "    sympy-1.13.3               |  py312hecd8cb5_1        15.0 MB\n",
      "    torchaudio-2.2.2           |        py312_cpu         4.9 MB  pytorch\n",
      "    torchvision-0.17.2         |        py312_cpu         6.7 MB  pytorch\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       121.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cpuonly            pytorch/noarch::cpuonly-2.0-0 \n",
      "  filelock           pkgs/main/osx-64::filelock-3.17.0-py312hecd8cb5_0 \n",
      "  gmp                pkgs/main/osx-64::gmp-6.3.0-h6d0c2b6_0 \n",
      "  gmpy2              pkgs/main/osx-64::gmpy2-2.2.1-py312h2cec913_0 \n",
      "  libjpeg-turbo      pkgs/main/osx-64::libjpeg-turbo-2.0.0-hca72f7f_0 \n",
      "  mpc                pkgs/main/osx-64::mpc-1.3.1-h46256e1_0 \n",
      "  mpfr               pkgs/main/osx-64::mpfr-4.2.1-h46256e1_0 \n",
      "  mpmath             pkgs/main/osx-64::mpmath-1.3.0-py312hecd8cb5_0 \n",
      "  networkx           pkgs/main/osx-64::networkx-3.4.2-py312hecd8cb5_0 \n",
      "  pytorch            pytorch/osx-64::pytorch-2.2.2-py3.12_0 \n",
      "  pytorch-mutex      pytorch/noarch::pytorch-mutex-1.0-cpu \n",
      "  sympy              pkgs/main/osx-64::sympy-1.13.3-py312hecd8cb5_1 \n",
      "  torchaudio         pytorch/osx-64::torchaudio-2.2.2-py312_cpu \n",
      "  torchvision        pytorch/osx-64::torchvision-0.17.2-py312_cpu \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "pytorch-2.2.2        | 90.0 MB   |                                       |   0% \n",
      "sympy-1.13.3         | 15.0 MB   |                                       |   0% \u001b[A\n",
      "\n",
      "torchvision-0.17.2   | 6.7 MB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "torchaudio-2.2.2     | 4.9 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "networkx-3.4.2       | 3.1 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mpmath-1.3.0         | 974 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.0.0  | 424 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gmpy2-2.2.1          | 218 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "filelock-3.17.0      | 38 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-mutex-1.0    | 3 KB      |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-2.2.2        | 90.0 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "networkx-3.4.2       | 3.1 MB    | 1                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "torchvision-0.17.2   | 6.7 MB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "torchaudio-2.2.2     | 4.9 MB    | 1                                     |   0% \u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.2.2        | 90.0 MB   | 2                                     |   1% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "networkx-3.4.2       | 3.1 MB    | ######9                               |  19% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "torchvision-0.17.2   | 6.7 MB    | ###1                                  |   9% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "torchaudio-2.2.2     | 4.9 MB    | ##8                                   |   8% \u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.2.2        | 90.0 MB   | 5                                     |   1% \u001b[A\n",
      "\n",
      "torchvision-0.17.2   | 6.7 MB    | ######8                               |  19% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "networkx-3.4.2       | 3.1 MB    | ################9                     |  46% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "torchaudio-2.2.2     | 4.9 MB    | #####7                                |  16% \u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.2.2        | 90.0 MB   | 8                                     |   2% \u001b[A\n",
      "\n",
      "torchvision-0.17.2   | 6.7 MB    | ###########7                          |  32% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "networkx-3.4.2       | 3.1 MB    | ############################          |  76% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "sympy-1.13.3         | 15.0 MB   | ###                                   |   8% \u001b[A\n",
      "\n",
      "\n",
      "pytorch-2.2.2        | 90.0 MB   | #1                                    |   3% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "torchvision-0.17.2   | 6.7 MB    | ###############7                      |  43% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "networkx-3.4.2       | 3.1 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "networkx-3.4.2       | 3.1 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "sympy-1.13.3         | 15.0 MB   | ####7                                 |  13% \u001b[A\n",
      "\n",
      "\n",
      "pytorch-2.2.2        | 90.0 MB   | #4                                    |   4% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "torchvision-0.17.2   | 6.7 MB    | #####################6                |  59% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mpmath-1.3.0         | 974 KB    | 6                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "sympy-1.13.3         | 15.0 MB   | ######2                               |  17% \u001b[A\n",
      "\n",
      "\n",
      "torchaudio-2.2.2     | 4.9 MB    | #############5                        |  37% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "torchvision-0.17.2   | 6.7 MB    | ##########################2           |  71% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-2.2.2        | 90.0 MB   | #7                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.2.2        | 90.0 MB   | ##1                                   |   6% \u001b[A\n",
      "\n",
      "\n",
      "torchaudio-2.2.2     | 4.9 MB    | ###############7                      |  43% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "torchvision-0.17.2   | 6.7 MB    | ##############################6       |  83% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mpmath-1.3.0         | 974 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.2.2        | 90.0 MB   | ##7                                   |   8% \u001b[A\n",
      "\n",
      "\n",
      "torchaudio-2.2.2     | 4.9 MB    | ####################6                 |  56% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.0.0  | 424 KB    | #3                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.2.2        | 90.0 MB   | ###3                                  |   9% \u001b[A\n",
      "\n",
      "\n",
      "torchaudio-2.2.2     | 4.9 MB    | #######################6              |  64% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.0.0  | 424 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "torchvision-0.17.2   | 6.7 MB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "torchvision-0.17.2   | 6.7 MB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "sympy-1.13.3         | 15.0 MB   | #################1                    |  46% \u001b[A\n",
      "\n",
      "\n",
      "pytorch-2.2.2        | 90.0 MB   | ###8                                  |  10% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gmpy2-2.2.1          | 218 KB    | ##7                                   |   7% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gmpy2-2.2.1          | 218 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.0.0  | 424 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "sympy-1.13.3         | 15.0 MB   | ###################5                  |  53% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-2.2.2        | 90.0 MB   | ####3                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "torchaudio-2.2.2     | 4.9 MB    | ##############################        |  81% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "filelock-3.17.0      | 38 KB     | ###############6                      |  42% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "filelock-3.17.0      | 38 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.2.2        | 90.0 MB   | ####8                                 |  13% \u001b[A\n",
      "\n",
      "\n",
      "torchaudio-2.2.2     | 4.9 MB    | #################################4    |  90% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mpmath-1.3.0         | 974 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cpuonly-2.0          | 2 KB      | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.2.2        | 90.0 MB   | #####3                                |  14% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-mutex-1.0    | 3 KB      | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cpuonly-2.0          | 2 KB      | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-mutex-1.0    | 3 KB      | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "torchaudio-2.2.2     | 4.9 MB    | ####################################5 |  99% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gmpy2-2.2.1          | 218 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gmpy2-2.2.1          | 218 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch-2.2.2        | 90.0 MB   | #####8                                |  16% \u001b[A\u001b[A\u001b[A\n",
      "sympy-1.13.3         | 15.0 MB   | ###########################5          |  74% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "filelock-3.17.0      | 38 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "filelock-3.17.0      | 38 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-2.2.2        | 90.0 MB   | ######8                               |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-mutex-1.0    | 3 KB      | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.2.2        | 90.0 MB   | #######5                              |  20% \u001b[A\n",
      "pytorch-2.2.2        | 90.0 MB   | ########8                             |  24% \u001b[A\n",
      "pytorch-2.2.2        | 90.0 MB   | ############                          |  33% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch-2.2.2        | 90.0 MB   | ###########################7          |  75% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.2.2        | 90.0 MB   | #############################5        |  80% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch-2.2.2        | 90.0 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch torchvision torchaudio cpuonly -c pytorch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenvconda)",
   "language": "python",
   "name": "myenvconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
